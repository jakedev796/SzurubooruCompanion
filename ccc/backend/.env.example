# ============================================================================
# Production .env â€” for use with docker-compose.yml (single s6 image)
# ============================================================================
# Copy this file:  cp ccc/backend/.env.example ccc/backend/.env
# For local development with separate services, see .env.dev.example instead.
#
# DATABASE_URL, REDIS_URL, JOB_DATA_DIR, and GALLERY_DL_CONFIG_FILE are baked
# into the production Dockerfile and do not need to be set here.

# ============================================================================
# REQUIRED: Encryption Key
# ============================================================================
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# Admin account setup happens through the web UI on first launch.

ENCRYPTION_KEY=your-generated-fernet-key-here

# --- Legacy: API key (unused; clients use JWT login) ---
# Kept for backwards compatibility. Browser extension and mobile app authenticate with username/password.
API_KEY=

# --- WD14 Tagger (ENV-based, requires restart to change) ---
# wd14_enabled, wd14_confidence_threshold, and wd14_max_tags are live settings managed via
# Settings > Global Settings in the dashboard. Only model/pool/threads require a restart.
WD14_MODEL=SmilingWolf/wd-swinv2-tagger-v3
# Number of threads for concurrent inference (used when process pool is off or GPU is active)
WD14_NUM_WORKERS=4
# Run inference in a dedicated subprocess to give PyTorch exclusive access to all CPU cores.
# Only beneficial when WORKER_CONCURRENCY=1. With multiple workers, leave this false so all
# workers share the thread pool and run inference concurrently instead of queuing behind one subprocess.
WD14_USE_PROCESS_POOL=false

# --- Worker ---
# Number of background workers to spawn. Requires a restart to change (workers start at boot),
# so this lives in ENV rather than the dashboard. Set to match your CPU core count for max throughput.
WORKER_CONCURRENCY=1

# --- Server ---
# TODO: HOST and PORT are loaded in config but not used; Dockerfile CMD hardcodes --host/--port.
# To utilize: run uvicorn from code (e.g. app/__main__.py) with settings.host/settings.port, or pass manually: uvicorn ... --host $HOST --port $PORT
HOST=0.0.0.0
PORT=21425
DEBUG=false
LOG_LEVEL=INFO
CORS_ORIGINS=*
