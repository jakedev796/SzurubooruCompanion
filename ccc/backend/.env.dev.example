# ============================================================================
# Development .env â€” for use with docker-compose.dev.yml (separate services)
# ============================================================================
# Copy this file:  cp ccc/backend/.env.dev.example ccc/backend/.env.dev
# For production (single s6 image), see .env.example instead.

# ============================================================================
# REQUIRED: Encryption Key
# ============================================================================
# Generate with: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# Admin account setup happens through the web UI on first launch.

ENCRYPTION_KEY=your-generated-fernet-key-here

# --- Database (Postgres) ---
# Hostname "postgres" matches the service name in docker-compose.dev.yml.
DATABASE_URL=postgresql+asyncpg://ccc:ccc@postgres:5432/ccc

# --- Redis ---
# Hostname "redis" matches the service name in docker-compose.dev.yml.
REDIS_URL=redis://redis:6379/0

# --- Legacy: API key (unused; clients use JWT login) ---
# Kept for backwards compatibility. Browser extension and mobile app authenticate with username/password.
API_KEY=

# --- WD14 Tagger (ENV-based, requires restart to change) ---
# wd14_enabled, wd14_confidence_threshold, and wd14_max_tags are live settings managed via
# Settings > Global Settings in the dashboard. Only model/pool/threads require a restart.
WD14_MODEL=SmilingWolf/wd-swinv2-tagger-v3
# Number of threads for concurrent inference (used when process pool is off or GPU is active)
WD14_NUM_WORKERS=4
# Run inference in a dedicated subprocess to give PyTorch exclusive access to all CPU cores.
# Only beneficial when WORKER_CONCURRENCY=1. With multiple workers, leave this false so all
# workers share the thread pool and run inference concurrently instead of queuing behind one subprocess.
WD14_USE_PROCESS_POOL=false

# --- Worker ---
# Number of background workers to spawn. Requires a restart to change (workers start at boot),
# so this lives in ENV rather than the dashboard. Set to match your CPU core count for max throughput.
WORKER_CONCURRENCY=1
JOB_DATA_DIR=/data/jobs

# --- Gallery-DL ---
# Path to gallery-dl config file
GALLERY_DL_CONFIG_FILE=/config.json

# --- Server ---
# TODO: HOST and PORT are loaded in config but not used; Dockerfile CMD hardcodes --host/--port.
# To utilize: run uvicorn from code (e.g. app/__main__.py) with settings.host/settings.port, or pass manually: uvicorn ... --host $HOST --port $PORT
HOST=0.0.0.0
PORT=21425
DEBUG=false
LOG_LEVEL=INFO
CORS_ORIGINS=*
